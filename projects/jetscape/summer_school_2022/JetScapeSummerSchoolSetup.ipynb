{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model setup is as follows: we have dijet asymmetry data prepared, where the asymmetry AJ is defined as the difference between the two jets divided by the sum. Specifically,\n",
    "\n",
    "$$A_{\\mathrm{j}} = \\frac{p_{\\mathrm{T, 1}} - p_{\\mathrm{T, 2}}}{p_{\\mathrm{T, 1}} + p_{\\mathrm{T, 2}}}$$\n",
    "\n",
    "We will construct a model to describe the energy loss observed in the dijet asymmetry.  For this model, we consider back-to-back dijets.  Each jet can lose energy, and the lost energy is parameterized as\n",
    "\n",
    "$$ \\Delta p_{\\mathrm{T}} / p_{\\mathrm{T}} \\sim A \\times Gaus(1, B)$$\n",
    "\n",
    "In addition to the energy loss contribution, we have extra \"apparent\" smearing on the AJ coming from the fact that we have other processes going on in the events (three jets etc).  It is parameterized as a Gaussian smearing on AJ with width C. So there are three total parameters: A, B, and C.\n",
    "\n",
    "The measurement is done in two bins of centrality.  One in central event, where (A, B, C) are all relevant, and another one in very peripheral event, where only the parameter (C) is relevant.\n",
    "\n",
    "The goal here in this notebook is to make the inputs needed for Bayesian inference to learn about A, B and C from the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "folder = Path('input/XJGammaToy/')\n",
    "folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xj or Aj\n",
    "#DataXMin        = 0.000\n",
    "#DataXMax        = 1.000\n",
    "#DataXBin        = 0.050\n",
    "# xj gamma\n",
    "DataXMin        = 0.000\n",
    "DataXMax        = 2.000\n",
    "DataXBin        = 0.125\n",
    "\n",
    "DataNBin        = int((DataXMax - DataXMin) / DataXBin)\n",
    "\n",
    "# how many design points do you want to generate?\n",
    "NDesign         = 100\n",
    "\n",
    "# What is the upper parameter range (one each for A, B, C)?\n",
    "# The lower range for each parameter is 0 by construction.\n",
    "# Hint: start with a large-range guess!  Then we can come back and reduce range\n",
    "#ParameterRanges = [(0, 1.0), (0.0, 1.0), (-0.5, 1.5), (0.1, 1.0)]\n",
    "ParameterRanges = [(0.025, 0.6), (0.025, 1.0), (0.025, 1.0), (0.1, 1.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"prediction\" function\n",
    "\n",
    "Let's write a function, where we do the required smearing, make a histogram on the final AJ, and return the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy.typing as npt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(A, B, C, N = 100000):\n",
    "    print(\"Running prediction with\", A, B, C)\n",
    "    \n",
    "    Hist = np.zeros(DataNBin)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Jet 1 and jet 2 PT (J1 and J2) after quenching.\n",
    "        # Assuming initial energy is 100 GeV, and (delta PT / PT) ~ gaus(A, B), calculate the final energy\n",
    "        # Jet PT = 100 GeV * (?)\n",
    "        # Note that the initial energy cancels out in AJ\n",
    "        # Useful function: np.random.normal(1, 2) gives you a random sampling with gaussian mean 1 and sigma 2\n",
    "        J1 = 100 * (1 - A * np.random.normal(1, B))\n",
    "        J2 = 100 * (1 - A * np.random.normal(1, B))\n",
    "        # Calculate AJ from the PTs\n",
    "        AJ = (J1 - J2) / (J1 + J2)\n",
    "        # Adding extra gaussian smearing from parameter C\n",
    "        AJ = AJ + np.random.normal(0, C)\n",
    "        # AJ is defined to be leading - subleading -> positive!\n",
    "        AJ = np.abs(AJ)\n",
    "\n",
    "        # put things into bins\n",
    "        Bin = int((AJ - DataXMin) / DataXBin)\n",
    "        if Bin < 0:   # underflow\n",
    "            Bin = 0\n",
    "        if Bin >= DataNBin:   # overflow\n",
    "            continue\n",
    "            # Bin = DataNBin - 1\n",
    "        \n",
    "        Hist[Bin] = Hist[Bin] + 1\n",
    "        \n",
    "    return Hist / N\n",
    "\n",
    "def predict_xjgamma(A: float, B: float, C: float, D: float, E: float, F: float, N: int = 100000) -> npt.NDArray[np.float64]:\n",
    "    print(f\"Running xj_gamma prediction with {A}, {B}, {C}, {D}\")\n",
    "    \n",
    "    hist = np.zeros(DataNBin)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Jet 1 and jet 2 PT (J1 and J2) after quenching.\n",
    "        # Assuming initial energy is 100 GeV, and (delta PT / PT) ~ gaus(A, B), calculate the final energy\n",
    "        # Jet PT = 100 GeV * (?)\n",
    "        # Note that the initial energy cancels out in AJ\n",
    "        # Useful function: np.random.normal(1, 2) gives you a random sampling with gaussian mean 1 and sigma 2\n",
    "        J1 = 100 * (1 - A * np.random.normal(0.1, B))\n",
    "        #J2 = 100 * (1 - np.random.normal(A, B))\n",
    "        J2 = 100 * (1 - C * np.random.normal(0.01, D))\n",
    "        # Calculate AJ from the PTs\n",
    "        XJ = J1 / J2\n",
    "        # Adding extra gaussian smearing from parameter C\n",
    "        XJ = XJ + np.random.normal(E, F)\n",
    "        # AJ is defined to be leading - subleading -> positive!\n",
    "        #AJ = np.abs(AJ)\n",
    "\n",
    "        # put things into bins\n",
    "        Bin = int((XJ - DataXMin) / DataXBin)\n",
    "        if Bin < 0:   # underflow\n",
    "            Bin = 0\n",
    "        if Bin >= DataNBin:   # overflow\n",
    "            continue\n",
    "            # Bin = DataNBin - 1\n",
    "        \n",
    "        hist[Bin] = hist[Bin] + 1\n",
    "        \n",
    "    return hist / N\n",
    "\n",
    "def predict_xj(A: float, B: float, C: float, D: float, N: int = 100000) -> npt.NDArray[np.float64]:\n",
    "    print(f\"Running xj prediction with {A}, {B}, {C}, {D}\")\n",
    "    \n",
    "    hist = np.zeros(DataNBin)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Jet 1 and jet 2 PT (J1 and J2) after quenching.\n",
    "        # Assuming initial energy is 100 GeV, and (delta PT / PT) ~ gaus(A, B), calculate the final energy\n",
    "        # Jet PT = 100 GeV * (?)\n",
    "        # Note that the initial energy cancels out in AJ\n",
    "        # Useful function: np.random.normal(1, 2) gives you a random sampling with gaussian mean 1 and sigma 2\n",
    "        #J1 = 100 * (1 - A * np.random.normal(1, B))\n",
    "        #J2 = 100 * (1 - A * np.random.normal(1, B))\n",
    "        J1 = 100 * (1 - np.abs(np.random.normal(A, B)))\n",
    "        #J2 = 100 * (1 - np.random.normal(A, B))\n",
    "        J2 = 100 * (1 - np.abs(np.random.normal(A, B)))\n",
    "        if J1 > J2:\n",
    "            J1, J2 = J2, J1\n",
    "        # Calculate XJ from the PTs\n",
    "        XJ = J1 / J2\n",
    "        # Adding extra gaussian smearing from parameter C\n",
    "        #XJ = XJ + np.random.normal(0.7, D)\n",
    "        XJ = XJ + np.random.normal(0.8, D)\n",
    "        # AJ is defined to be leading - subleading -> positive!\n",
    "        # OVERFLOW IS THE ISSUE! Too broad!\n",
    "        if XJ > 2:\n",
    "            XJ = 2\n",
    "        if XJ > 1:\n",
    "            print(XJ)\n",
    "            XJ = XJ - 2 * (XJ - 1)\n",
    "            print(XJ)\n",
    "        #AJ = np.abs(AJ)\n",
    "\n",
    "        # put things into bins\n",
    "        Bin = int((XJ - DataXMin) / DataXBin)\n",
    "        #if Bin == 0:\n",
    "        #    print(J1, J2)\n",
    "        if Bin < 0:   # underflow\n",
    "            Bin = 0\n",
    "        if Bin >= DataNBin:   # overflow\n",
    "            continue\n",
    "            # Bin = DataNBin - 1\n",
    "        \n",
    "        hist[Bin] = hist[Bin] + 1\n",
    "        \n",
    "    return hist / N\n",
    "\n",
    "\n",
    "def predict_xjgamma_smeared(A: float, B: float, C: float, D: float, N: int = 100000) -> npt.NDArray[np.float64]:\n",
    "    print(f\"Running xj_gamma smeared prediction with {A}, {B}, {C}, {D}\")\n",
    "    \n",
    "    bins = np.linspace(DataXMin, DataXMax, int((DataXMax - DataXMin) / DataXBin) + 1)\n",
    "    hists = []\n",
    "    #hist = np.zeros(DataNBin)\n",
    "    \n",
    "    xj_values = []\n",
    "    for i in range(N):\n",
    "        # Jet 1 and jet 2 PT (J1 and J2) after quenching.\n",
    "        # Assuming initial energy is 100 GeV, and (delta PT / PT) ~ gaus(A, B), calculate the final energy\n",
    "        # Jet PT = 100 GeV * (?)\n",
    "        # Note that the initial energy cancels out in AJ\n",
    "        # Useful function: np.random.normal(1, 2) gives you a random sampling with gaussian mean 1 and sigma 2\n",
    "        #J1 = 100 * (1 - np.random.normal(A, B))\n",
    "        J1 = 100 * (1 - np.random.normal(A, B))\n",
    "        #J2 = 100 * (1 - np.random.normal(A, B))\n",
    "        J2 = 100\n",
    "        # Calculate AJ from the PTs\n",
    "        XJ = J1 / J2\n",
    "        # Adding extra gaussian smearing from parameter C\n",
    "        smear = np.random.normal(C, D)\n",
    "        xj_original = XJ\n",
    "        XJ = XJ + smear\n",
    "        # XJ must be positive definition. If the smearing is too large, set to 0\n",
    "        if XJ < 0:\n",
    "            XJ = 0\n",
    "        # AJ is defined to be leading - subleading -> positive!\n",
    "        #AJ = np.abs(AJ)\n",
    "\n",
    "        h, _ = np.histogram(a=XJ, bins=bins)\n",
    "        print(f\"{h}\")\n",
    "        hists.append(h / h.sum())\n",
    "\n",
    "        ## put things into bins\n",
    "        #Bin = int((XJ - DataXMin) / DataXBin)\n",
    "        #if Bin == 0:\n",
    "        #    pass\n",
    "        #    #print(f\"{J1=}, {J2=}, {XJ=}, {smear=}, {xj_original=}\")\n",
    "        #if Bin < 0:   # underflow\n",
    "        #    Bin = 0\n",
    "        #if Bin >= DataNBin:   # overflow\n",
    "        #    continue\n",
    "        #    # Bin = DataNBin - 1\n",
    "        \n",
    "        #hist[Bin] = hist[Bin] + 1\n",
    "        \n",
    "    #return hist / N\n",
    "    return hists[0] if len(hists) == 1 else hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xjgamma_smeared_full(A: float, B: float, C: float, D: float, N: int = 100000) -> npt.NDArray[np.float64]:\n",
    "    print(f\"Running xj_gamma smeared prediction with {A}, {B}, {C}, {D}\")\n",
    "    \n",
    "    # Jet 1 and jet 2 PT (J1 and J2) after quenching.\n",
    "    # Assuming initial energy is 100 GeV, and (delta PT / PT) ~ gaus(A, B), calculate the final energy\n",
    "    # Jet PT = 100 GeV * (?)\n",
    "    # Note that the initial energy cancels out in AJ\n",
    "    # Useful function: np.random.normal(1, 2) gives you a random sampling with gaussian mean 1 and sigma 2\n",
    "    #J1 = 100 * (1 - np.random.normal(A, B))\n",
    "    J1 = 100 * (1 - np.random.normal(A, B, size=(N, len(A))))\n",
    "    #J2 = 100 * (1 - np.random.normal(A, B))\n",
    "    J2 = 100\n",
    "    # Calculate AJ from the PTs\n",
    "    XJ = J1 / J2\n",
    "    # Adding extra gaussian smearing from parameter C\n",
    "    smear = np.random.normal(C, D, size=(N, len(A)))\n",
    "    xj_original = XJ\n",
    "    XJ = XJ + smear\n",
    "    # XJ must be positive definition. If the smearing is too large, set to 0\n",
    "    _mask = (XJ < 0)\n",
    "    XJ[_mask] = 0\n",
    "    # AJ is defined to be leading - subleading -> positive!\n",
    "    #AJ = np.abs(AJ)\n",
    "\n",
    "    # put things into bins\n",
    "    bins = np.linspace(DataXMin, DataXMax, int((DataXMax - DataXMin) / DataXBin) + 1)\n",
    "    #Bin = int((XJ - DataXMin) / DataXBin)\n",
    "    #if Bin == 0:\n",
    "    #    pass\n",
    "    #    #print(f\"{J1=}, {J2=}, {XJ=}, {smear=}, {xj_original=}\")\n",
    "    #if Bin < 0:   # underflow\n",
    "    #    Bin = 0\n",
    "    #if Bin >= DataNBin:   # overflow\n",
    "    #    continue\n",
    "    #    # Bin = DataNBin - 1\n",
    "    \n",
    "    #hist[Bin] = hist[Bin] + 1\n",
    "\n",
    "    #h, _ = np.histogram2d(x=XJ, y=bins=bins)\n",
    "    #h, _ = np.histogram(XJ, y=bins=bins)\n",
    "   \n",
    "    #return hist / N\n",
    "    #return h / h.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xjgamma_smeared_fix(A: float, B: float, C: float, D: float, n_samples: int = 100000) -> npt.NDArray[np.float64]:\n",
    "    print(f\"Running xj_gamma smeared prediction with {A}, {B}, {C}, {D}\")\n",
    "    \n",
    "    bins = np.linspace(DataXMin, DataXMax, int((DataXMax - DataXMin) / DataXBin) + 1)\n",
    "    #hists = []\n",
    "    #hist = np.zeros(DataNBin)\n",
    "\n",
    "    # Jet 1 and jet 2 PT (J1 and J2) after quenching.\n",
    "    # Assuming initial energy is 100 GeV, and (delta PT / PT) ~ gaus(A, B), calculate the final energy\n",
    "    # Jet PT = 100 GeV * (?)\n",
    "    # Note that the initial energy cancels out in AJ\n",
    "    # Useful function: np.random.normal(1, 2) gives you a random sampling with gaussian mean 1 and sigma 2\n",
    "    #J1 = 100 * (1 - np.random.normal(A, B))\n",
    "    J1 = 100 * (1 - np.random.normal(A, B, size=n_samples))\n",
    "    #J2 = 100 * (1 - np.random.normal(A, B))\n",
    "    J2 = 100\n",
    "    # Calculate AJ from the PTs\n",
    "    XJ = J1 / J2\n",
    "    # Adding extra gaussian smearing from parameter C\n",
    "    smear = np.random.normal(C, D, size=n_samples)\n",
    "    xj_original = XJ\n",
    "    #XJ = XJ - smear\n",
    "    XJ = XJ + smear\n",
    "    # XJ must be positive definition. If the smearing is too large, we leave them below 0\n",
    "    # and they are subsequently ignored in the histogramming\n",
    "    #_mask = (XJ < 0)\n",
    "    #XJ[_mask] = 0\n",
    "    # AJ is defined to be leading - subleading -> positive!\n",
    "    #AJ = np.abs(AJ)\n",
    "\n",
    "    #print(f\"{smear=}, {xj_original=}\")\n",
    "    #return XJ\n",
    "    h, _ = np.histogram(a=XJ, bins=bins)\n",
    "    #print(f\"{h=}\")\n",
    "    #hists.append(h / h.sum())\n",
    "\n",
    "    ## put things into bins\n",
    "    #Bin = int((XJ - DataXMin) / DataXBin)\n",
    "    #if Bin == 0:\n",
    "    #    pass\n",
    "    #    #print(f\"{J1=}, {J2=}, {XJ=}, {smear=}, {xj_original=}\")\n",
    "    #if Bin < 0:   # underflow\n",
    "    #    Bin = 0\n",
    "    #if Bin >= DataNBin:   # overflow\n",
    "    #    continue\n",
    "    #    # Bin = DataNBin - 1\n",
    "    \n",
    "    #hist[Bin] = hist[Bin] + 1\n",
    "        \n",
    "    #return hist / N\n",
    "    #return hists[0] if len(hists) == 1 else hists\n",
    "    return h / h.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the prediction (cross check for yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predicting one point - to see if the output makes sense or not\n",
    "# Once you are happy, we move on!\n",
    "#example_prediction = predict_xjgamma(1, 0.25, 0, 0, 0, 0.3)\n",
    "#example_prediction = predict_xj(0.1, 0.3, 1, 1.5)\n",
    "example_prediction = predict_xjgamma_smeared_fix(1, 0, 1.71608035669855451, 0.142)\n",
    "example_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prediction.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively (or in addition), plot the AJ distribution for our single point\n",
    "import matplotlib.pyplot as plt\n",
    "#example_prediction = predict_xj(0.3, 0.3, 0, 0.3)\n",
    "#example_prediction = predict_xjgamma_smeared(0.2, 0.6, 0.2, 0.3)\n",
    "example_prediction = predict_xjgamma_smeared_fix(0.05, 0.3, -0.1, 0.3)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(np.arange(DataXMin, DataXMax, DataXBin) + (DataXBin / 2), example_prediction, marker=\"o\", linestyle=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = np.arange(DataXMin, DataXMax, DataXBin) + (DataXBin / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "line, = ax.plot(_x, predict_xj(A=0.1, B=0.3, C=1, D=0.3))\n",
    "\n",
    "x = np.array([1,2,3,4,5])\n",
    "\n",
    "def update(A = 1, B = 0, C = 0):\n",
    "    line.set_ydata(f(x,A,B,C))\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "interact(update, A = (0,1,0.1), B = (0,1,0.1), C = (1,1,0.1), D = (1,1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import numpy.typing as npt\n",
    "_x = np.linspace(0, 2, 20)\n",
    "\n",
    "def gaussian(\n",
    "    x: Union[npt.NDArray[np.float64], float], mean: float, sigma: float\n",
    ") -> Union[npt.NDArray[np.float64], float]:\n",
    "     r\"\"\"Normalized gaussian.\n",
    "\n",
    "     .. math::\n",
    "\n",
    "         f = 1 / \\sqrt{2 * \\pi * \\sigma^{2}} * \\exp{-\\frac{(x - \\mu)^{2}}{(2 * \\sigma^{2}}}\n",
    "\n",
    "     Args:\n",
    "         x: Value(s) where the gaussian should be evaluated.\n",
    "         mean: Mean of the gaussian distribution.\n",
    "         sigma: Width of the gaussian distribution.\n",
    "     Returns:\n",
    "         Calculated gaussian value(s).\n",
    "     \"\"\"\n",
    "     return 1.0 / np.sqrt(2 * np.pi * np.square(sigma)) * np.exp(-1.0 / 2.0 * np.square((x - mean) / sigma))  # type: ignore\n",
    "\n",
    "def extended_gaussian(\n",
    "    x: Union[npt.NDArray[np.float64], float], mean: float, sigma: float, amplitude: float\n",
    ") -> Union[npt.NDArray[np.float64], float]:\n",
    "    r\"\"\"Extended gaussian.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        f = A / \\sqrt{2 * \\pi * \\sigma^{2}} * \\exp{-\\frac{(x - \\mu)^{2}}{(2 * \\sigma^{2}}}\n",
    "\n",
    "    Args:\n",
    "        x: Value(s) where the gaussian should be evaluated.\n",
    "        mean: Mean of the gaussian distribution.\n",
    "        sigma: Width of the gaussian distribution.\n",
    "        amplitude: Amplitude of the gaussian.\n",
    "    Returns:\n",
    "        Calculated gaussian value(s).\n",
    "    \"\"\"\n",
    "    return amplitude / np.sqrt(2 * np.pi * np.square(sigma)) * np.exp(-1.0 / 2.0 * np.square((x - mean) / sigma))  # type: ignore\n",
    "\n",
    "def test_func(x: npt.NDArray[np.float64], a: float, b: float, c: float, d: float, e: float) -> float:\n",
    "    return e*(1-gaussian(x, a, b)) - gaussian(x, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = np.arange(DataXMin, DataXMax, DataXBin) + (DataXBin / 2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(_x, extended_gaussian(_x, 1, 0.1, 1) + extended_gaussian(_x, 1, 0.8, 3), marker=\"o\", alpha=0.5)\n",
    "ax.plot(_x, extended_gaussian(_x, 1, 0.1, 1), marker=\"o\", alpha=0.5)\n",
    "ax.plot(_x, extended_gaussian(_x, 1, 0.8, 3), marker=\"o\", alpha=0.5)\n",
    "#ax.plot(_x, extended_gaussian(_x, 1, 1, 5), marker=\"o\", alpha=0.5)\n",
    "ax.plot(_x, 5*gaussian(_x, 1, 1), marker=\"s\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the design points\n",
    "\n",
    "Let's start with a very simple random array :D\n",
    "\n",
    "In reality we would use something more complicated to distribute the points better, but let's start simple.  Fancy stuff is just a better way to achieve the same purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design = np.random.rand(NDesign, 3) * ParameterRanges\n",
    "design = np.array([\n",
    "    np.random.uniform(low=p[0], high=p[1], size=NDesign)\n",
    "    for p in ParameterRanges\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return x + y\n",
    "\n",
    "my_x = np.random.rand(10)\n",
    "my_y = np.random.rand(10)\n",
    "np.allclose(f(my_x, my_y), my_x + my_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.array([\n",
    "    #np.vectorize(predict_xjgamma_smeared_fix)(A=design[0, :], B=design[1, :], C=design[2, :], D=design[3, :]) for d in design\n",
    "    predict_xjgamma_smeared_fix(A=d[0], B=d[1], C=d[2], D=d[3]) for d in design.T\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xjgamma_smeared_fix(A=design[-1, 0], B=design[-1, 1], C=design[-1, 2], D=design[-1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model predictions\n",
    "\n",
    "Let's loop over the design points, and call the predict function we just wrote to make a big table!\n",
    "\n",
    "This step takes a while, like a few minutes.  Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction for \"central\" data\n",
    "#Y1 = [predict_xjgamma_smeared(i[0], i[1], i[2]) for i in design]\n",
    "Y1 = np.array([\n",
    "    predict_xjgamma_smeared_fix(A=d[0], B=d[1], C=d[2], D=d[3]) for d in design\n",
    "])\n",
    "# Generate prediction for \"peripheral\" data.  Note here A and B are irrelevant.  So we set them to 0\n",
    "#Y2 = [predict_xjgamma_smeared(0, 0, i[2]) for i in design]\n",
    "Y2 = np.array([\n",
    "    # A = 1 so that the XJ cancels out to 0, and then it's just the second term that dominates\n",
    "    predict_xjgamma_smeared_fix(A=1, B=0.02, C=d[2], D=d[3]) for d in design\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = np.array([\n",
    "    # A = 1 so that the XJ cancels out to 0, and then it's just the second term that dominates\n",
    "    predict_xjgamma_smeared_fix(A=1, B=0.02, C=d[2], D=d[3]) for d in design[26:30]\n",
    "])\n",
    "#Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write everything out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder / 'Prediction_Selection1.dat', 'w') as f:\n",
    "    f.write('# Version 1.0\\n')\n",
    "    f.write('# Data Data_Selection1.dat\\n')\n",
    "    f.write('# Design Design.dat\\n')\n",
    "    np.savetxt(f, np.transpose(Y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder / 'Prediction_Selection2.dat', 'w') as f:\n",
    "    f.write('# Version 1.0\\n')\n",
    "    f.write('# Data Data_Selection2.dat\\n')\n",
    "    f.write('# Design Design.dat\\n')\n",
    "    np.savetxt(f, np.transpose(Y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder / 'Design.dat', 'w') as f:\n",
    "    f.write('# Version 1.0\\n')\n",
    "    f.write(f'# Parameter {\" \".join(\"A B C D E F G H I J K L\".split()[:design.shape[1]])}\\n')\n",
    "    np.savetxt(f, design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Truth = [0.50, 0.25, 0.10]\n",
    "\n",
    "DataY1 = Predict(Truth[0], Truth[1], Truth[2], N = 100000)\n",
    "DataY2 = Predict(0, 0, Truth[2], N = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XMin = np.array(range(0, DataNBin)) * DataXBin\n",
    "XMax = np.array(range(1, DataNBin + 1)) * DataXBin\n",
    "\n",
    "Stat = 0.001\n",
    "Sys = 0.010\n",
    "\n",
    "Data1 = np.zeros((DataNBin, 7))\n",
    "Data2 = np.zeros((DataNBin, 7))\n",
    "\n",
    "Data1[:,0] = XMin\n",
    "Data1[:,1] = XMax\n",
    "Data1[:,2] = DataY1\n",
    "Data1[:,3] = Stat\n",
    "Data1[:,4] = Stat\n",
    "Data1[:,5] = Sys\n",
    "Data1[:,6] = Sys\n",
    "\n",
    "Data2[:,0] = XMin\n",
    "Data2[:,1] = XMax\n",
    "Data2[:,2] = DataY2\n",
    "Data2[:,3] = Stat\n",
    "Data2[:,4] = Stat\n",
    "Data2[:,5] = Sys\n",
    "Data2[:,6] = Sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder / 'Data_Selection1.dat', 'w') as f:\n",
    "    f.write('# Version 1.0\\n')\n",
    "    f.write('# DOI None\\n')\n",
    "    f.write('# Source None\\n')\n",
    "    f.write('# Experiment JetScape\\n')\n",
    "    f.write('# System PbPb5020\\n')\n",
    "    f.write('# Centrality 0to10\\n')\n",
    "    f.write('# XY AJ DNDAJ\\n')\n",
    "    f.write('# Label xmin xmax y stat,low stat,high sys,low sys,high\\n')\n",
    "    np.savetxt(f, Data1)\n",
    "    \n",
    "with open(folder / 'Data_Selection2.dat', 'w') as f:\n",
    "    f.write('# Version 1.0\\n')\n",
    "    f.write('# DOI None\\n')\n",
    "    f.write('# Source None\\n')\n",
    "    f.write('# Experiment JetScape\\n')\n",
    "    f.write('# System PbPb5020\\n')\n",
    "    f.write('# Centrality 70to90\\n')\n",
    "    f.write('# XY AJ DNDAJ\\n')\n",
    "    f.write('# Label xmin xmax y stat,low stat,high sys,low sys,high\\n')\n",
    "    np.savetxt(f, Data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d65bb7f5f25d512d5b31173bad01016a3b501790a1361b769a5765daf7b2eab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
